{"ast":null,"code":"export var TOKEN_BEGIN_TAG = 'begin tag';\nexport var TOKEN_END_TAG = 'end tag';\nexport var TOKEN_TEXT = 'text';\n\nvar replaceCodes = function replaceCodes(text) {\n  return text.replace(/&quot;/g, '\"').replace(/&lt;/g, '<').replace(/&gt;/g, '>');\n};\n\nexport var scan = function scan(text) {\n  if (text === undefined || text === null || text === '') {\n    return [{\n      type: TOKEN_TEXT,\n      lexeme: text\n    }];\n  }\n\n  var tagRegex = /<([\\w-]+)>|<\\/([\\w-]*)>/;\n  var tokens = [];\n  var remainingText = text;\n\n  while (remainingText.length > 0) {\n    var tag = tagRegex.exec(remainingText);\n\n    if (!tag) {\n      var lexeme = replaceCodes(remainingText);\n      tokens.push({\n        type: TOKEN_TEXT,\n        lexeme: lexeme\n      });\n      remainingText = '';\n      break;\n    }\n\n    if (tag.index > 0) {\n      var headText = remainingText.substring(0, tag.index);\n\n      var _lexeme = replaceCodes(headText);\n\n      tokens.push({\n        type: TOKEN_TEXT,\n        lexeme: _lexeme\n      });\n      remainingText = remainingText.substring(tag.index);\n    }\n\n    var styleName = tag[1] || tag[2];\n\n    if (tag[0].startsWith('</')) {\n      tokens.push({\n        type: TOKEN_END_TAG,\n        lexeme: styleName\n      });\n    } else {\n      tokens.push({\n        type: TOKEN_BEGIN_TAG,\n        lexeme: styleName\n      });\n    }\n\n    remainingText = remainingText.substring(tag[0].length);\n  }\n\n  return tokens;\n};","map":{"version":3,"sources":["/home/mayank/Study/TPE/h1/assist-learning/assist/node_modules/react-native-styled-text/StyledText/lexicalAnalyzer.js"],"names":["TOKEN_BEGIN_TAG","TOKEN_END_TAG","TOKEN_TEXT","replaceCodes","text","replace","scan","undefined","type","lexeme","tagRegex","tokens","remainingText","length","tag","exec","push","index","headText","substring","styleName","startsWith"],"mappings":"AAKA,OAAO,IAAMA,eAAe,GAAG,WAAxB;AACP,OAAO,IAAMC,aAAa,GAAG,SAAtB;AACP,OAAO,IAAMC,UAAU,GAAG,MAAnB;;AAEP,IAAMC,YAAY,GAAG,SAAfA,YAAe,CAACC,IAAD,EAAkB;AACrC,SAAOA,IAAI,CACVC,OADM,CACE,SADF,EACa,GADb,EAENA,OAFM,CAEE,OAFF,EAEW,GAFX,EAGNA,OAHM,CAGE,OAHF,EAGW,GAHX,CAAP;AAID,CALD;;AAOA,OAAO,IAAMC,IAAI,GAAG,SAAPA,IAAO,CAACF,IAAD,EAAgC;AAClD,MAAIA,IAAI,KAAKG,SAAT,IAAsBH,IAAI,KAAK,IAA/B,IAAuCA,IAAI,KAAK,EAApD,EAAwD;AACtD,WAAO,CAAC;AAAEI,MAAAA,IAAI,EAAEN,UAAR;AAAoBO,MAAAA,MAAM,EAAEL;AAA5B,KAAD,CAAP;AACD;;AAED,MAAMM,QAAQ,GAAG,yBAAjB;AACA,MAAMC,MAAM,GAAG,EAAf;AAEA,MAAIC,aAAa,GAAGR,IAApB;;AACA,SAAOQ,aAAa,CAACC,MAAd,GAAuB,CAA9B,EAAiC;AAC/B,QAAMC,GAAG,GAAGJ,QAAQ,CAACK,IAAT,CAAcH,aAAd,CAAZ;;AAEA,QAAI,CAACE,GAAL,EAAU;AACR,UAAML,MAAM,GAAGN,YAAY,CAACS,aAAD,CAA3B;AACAD,MAAAA,MAAM,CAACK,IAAP,CAAY;AAAER,QAAAA,IAAI,EAAEN,UAAR;AAAoBO,QAAAA,MAAM,EAANA;AAApB,OAAZ;AACAG,MAAAA,aAAa,GAAG,EAAhB;AACA;AACD;;AAED,QAAIE,GAAG,CAACG,KAAJ,GAAY,CAAhB,EAAmB;AACjB,UAAMC,QAAQ,GAAGN,aAAa,CAACO,SAAd,CAAwB,CAAxB,EAA2BL,GAAG,CAACG,KAA/B,CAAjB;;AACA,UAAMR,OAAM,GAAGN,YAAY,CAACe,QAAD,CAA3B;;AACAP,MAAAA,MAAM,CAACK,IAAP,CAAY;AAAER,QAAAA,IAAI,EAAEN,UAAR;AAAoBO,QAAAA,MAAM,EAANA;AAApB,OAAZ;AACAG,MAAAA,aAAa,GAAGA,aAAa,CAACO,SAAd,CAAwBL,GAAG,CAACG,KAA5B,CAAhB;AACD;;AAED,QAAMG,SAAS,GAAGN,GAAG,CAAC,CAAD,CAAH,IAAUA,GAAG,CAAC,CAAD,CAA/B;;AACA,QAAIA,GAAG,CAAC,CAAD,CAAH,CAAOO,UAAP,CAAkB,IAAlB,CAAJ,EAA6B;AAC3BV,MAAAA,MAAM,CAACK,IAAP,CAAY;AAAER,QAAAA,IAAI,EAAEP,aAAR;AAAuBQ,QAAAA,MAAM,EAAEW;AAA/B,OAAZ;AACD,KAFD,MAEO;AACLT,MAAAA,MAAM,CAACK,IAAP,CAAY;AAAER,QAAAA,IAAI,EAAER,eAAR;AAAyBS,QAAAA,MAAM,EAAEW;AAAjC,OAAZ;AACD;;AAEDR,IAAAA,aAAa,GAAGA,aAAa,CAACO,SAAd,CAAwBL,GAAG,CAAC,CAAD,CAAH,CAAOD,MAA/B,CAAhB;AACD;;AAED,SAAOF,MAAP;AACD,CArCM","sourcesContent":["export type Token = {\n  type: string,\n  lexeme: string,\n}\n\nexport const TOKEN_BEGIN_TAG = 'begin tag';\nexport const TOKEN_END_TAG = 'end tag';\nexport const TOKEN_TEXT = 'text';\n\nconst replaceCodes = (text: string) => {\n  return text\n  .replace(/&quot;/g, '\"')\n  .replace(/&lt;/g, '<')\n  .replace(/&gt;/g, '>')\n}\n\nexport const scan = (text: string): Array<Token> => {\n  if (text === undefined || text === null || text === '') {\n    return [{ type: TOKEN_TEXT, lexeme: text }];\n  }\n\n  const tagRegex = /<([\\w-]+)>|<\\/([\\w-]*)>/;\n  const tokens = [];\n\n  let remainingText = text;\n  while (remainingText.length > 0) {\n    const tag = tagRegex.exec(remainingText);\n\n    if (!tag) {\n      const lexeme = replaceCodes(remainingText);\n      tokens.push({ type: TOKEN_TEXT, lexeme });\n      remainingText = '';\n      break;\n    }\n\n    if (tag.index > 0) {\n      const headText = remainingText.substring(0, tag.index);\n      const lexeme = replaceCodes(headText);\n      tokens.push({ type: TOKEN_TEXT, lexeme });\n      remainingText = remainingText.substring(tag.index);\n    }\n\n    const styleName = tag[1] || tag[2];\n    if (tag[0].startsWith('</')) {\n      tokens.push({ type: TOKEN_END_TAG, lexeme: styleName });\n    } else {\n      tokens.push({ type: TOKEN_BEGIN_TAG, lexeme: styleName });\n    }\n\n    remainingText = remainingText.substring(tag[0].length);\n  }\n\n  return tokens;\n};\n"]},"metadata":{},"sourceType":"module"}